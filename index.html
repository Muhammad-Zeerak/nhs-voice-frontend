<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NHS Connect | AI Receptionist</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        :root {
            --primary: #005EB8; /* NHS Blue */
            --primary-dark: #003087;
            --accent: #00A9CE; /* Bright Cyan */
            --bg-grad-start: #f0f7fa;
            --bg-grad-end: #e1e9f0;
            --surface: #ffffff;
            --text-main: #1f2937;
            --text-sub: #6b7280;
            --error: #ef4444;
        }

        body {
            font-family: 'Inter', sans-serif;
            background: linear-gradient(135deg, var(--bg-grad-start) 0%, var(--bg-grad-end) 100%);
            height: 100vh;
            margin: 0;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }

        /* --- Main Card Container --- */
        .app-container {
            background: var(--surface);
            width: 100%;
            max-width: 420px;
            border-radius: 24px;
            box-shadow: 
                0 20px 25px -5px rgba(0, 0, 0, 0.1), 
                0 10px 10px -5px rgba(0, 0, 0, 0.04);
            padding: 40px 30px;
            text-align: center;
            position: relative;
            overflow: hidden;
            transition: transform 0.3s ease;
        }

        /* NHS Logo / Badge */
        .badge {
            background-color: var(--primary);
            color: white;
            padding: 6px 16px;
            font-weight: 700;
            font-size: 14px;
            border-radius: 4px;
            display: inline-block;
            margin-bottom: 20px;
            letter-spacing: 0.5px;
        }

        h1 {
            color: var(--text-main);
            font-size: 24px;
            font-weight: 700;
            margin: 0 0 10px 0;
        }

        p.subtitle {
            color: var(--text-sub);
            font-size: 15px;
            margin-bottom: 40px;
            line-height: 1.5;
        }

        /* --- Microphone Button Area --- */
        .mic-wrapper {
            position: relative;
            height: 140px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 30px;
        }

        /* The Pulse Animation Rings */
        .pulse-ring {
            position: absolute;
            width: 100px;
            height: 100px;
            border-radius: 50%;
            background: var(--primary);
            opacity: 0;
            transform: scale(0.8);
        }

        /* Active State Animation */
        .mic-wrapper.active .pulse-ring {
            animation: pulse-animation 2s infinite;
        }
        .mic-wrapper.active .pulse-ring:nth-child(2) {
            animation-delay: 0.5s;
        }

        @keyframes pulse-animation {
            0% { transform: scale(0.8); opacity: 0.4; }
            100% { transform: scale(2.5); opacity: 0; }
        }

        /* The Button Itself */
        #mic-btn {
            width: 90px;
            height: 90px;
            border-radius: 50%;
            background: linear-gradient(135deg, var(--primary), var(--primary-dark));
            border: none;
            cursor: pointer;
            z-index: 10;
            box-shadow: 0 10px 20px rgba(0, 94, 184, 0.3);
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s cubic-bezier(0.25, 0.8, 0.25, 1);
            position: relative;
            outline: none;
            -webkit-tap-highlight-color: transparent;
        }

        #mic-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 15px 30px rgba(0, 94, 184, 0.4);
        }

        #mic-btn:active {
            transform: scale(0.95);
        }

        #mic-btn svg {
            width: 40px;
            height: 40px;
            fill: white;
            transition: transform 0.3s ease;
        }

        /* --- Status & Response --- */
        #status-text {
            font-weight: 600;
            color: var(--primary);
            min-height: 24px;
            margin-bottom: 20px;
            font-size: 16px;
            transition: color 0.3s ease;
        }

        .chat-bubble {
            background: #F3F4F6;
            color: var(--text-main);
            padding: 20px;
            border-radius: 16px;
            border-bottom-left-radius: 4px;
            text-align: left;
            font-size: 15px;
            line-height: 1.6;
            box-shadow: inset 0 1px 2px rgba(0,0,0,0.06);
            opacity: 0;
            transform: translateY(10px);
            transition: all 0.4s ease;
            display: none; /* Hidden initially */
            position: relative;
        }
        
        /* Little triangle for chat bubble */
        .chat-bubble::before {
            content: '';
            position: absolute;
            bottom: 0;
            left: -8px;
            width: 0;
            height: 0;
            border: 10px solid transparent;
            border-right-color: #F3F4F6;
            border-bottom: 0;
            margin-bottom: 0;
        }

        .chat-bubble.visible {
            opacity: 1;
            transform: translateY(0);
            display: block;
        }

        /* --- States --- */
        .is-recording #mic-btn {
            background: #ef4444; /* Red when recording */
            box-shadow: 0 10px 20px rgba(239, 68, 68, 0.3);
        }
        .is-processing #status-text {
            color: var(--text-sub);
            animation: blink 1.5s infinite;
        }

        @keyframes blink {
            50% { opacity: 0.5; }
        }

        /* --- Mobile Responsiveness --- */
        @media (max-width: 480px) {
            .app-container {
                height: 100vh;
                border-radius: 0;
                display: flex;
                flex-direction: column;
                justify-content: center;
                box-shadow: none;
            }
        }
    </style>
</head>
<body>

    <div class="app-container">
        <div class="badge">NHS Connect</div>

        <h1>Virtual Receptionist</h1>
        <p class="subtitle">Press and hold the button to speak.</p>

        <div id="status-text">Ready</div>

        <div class="mic-wrapper" id="mic-wrapper">
            <div class="pulse-ring"></div>
            <div class="pulse-ring"></div>
            
            <button id="mic-btn" 
                onmousedown="startRecording()" 
                onmouseup="stopRecording()" 
                ontouchstart="startRecording()" 
                ontouchend="stopRecording()">
                
                <svg viewBox="0 0 24 24">
                    <path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 2.34 9 5v6c0 1.66 1.34 3 3 3z"/>
                    <path d="M17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/>
                </svg>
            </button>
        </div>

        <div id="response-box" class="chat-bubble"></div>
    </div>

    <script>
        // ==========================================
        //  CONFIG: PASTE YOUR N8N URL HERE
        // ==========================================
        const WEBHOOK_URL = "https://i-zeerak.app.n8n.cloud/webhook-test/voice-chat"; 
        // ==========================================

        let mediaRecorder;
        let audioChunks = [];
        const statusEl = document.getElementById('status-text');
        const micWrapper = document.getElementById('mic-wrapper');
        const responseBox = document.getElementById('response-box');
        
        // Session ID Handling
        let sessionId = localStorage.getItem('nhs_session_id');
        if (!sessionId) {
            sessionId = Math.random().toString(36).substring(7);
            localStorage.setItem('nhs_session_id', sessionId);
        }

        // --- Recording Functions ---

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = event => audioChunks.push(event.data);
                mediaRecorder.onstop = sendAudio;
                
                mediaRecorder.start();

                // UI Updates
                micWrapper.classList.add('active');
                document.body.classList.add('is-recording');
                statusEl.innerText = "Listening...";
                statusEl.style.color = "#ef4444";
                
                // Hide previous response
                responseBox.classList.remove('visible');

            } catch (err) {
                console.error("Mic Error:", err);
                statusEl.innerText = "Microphone access required.";
                statusEl.style.color = "var(--error)";
            }
        }

        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                
                // UI Updates
                micWrapper.classList.remove('active');
                document.body.classList.remove('is-recording');
                document.body.classList.add('is-processing');
                
                statusEl.innerText = "Thinking...";
                statusEl.style.color = "var(--text-sub)";
            }
        }

        // --- Networking & AI ---

        async function sendAudio() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const formData = new FormData();
            formData.append('data', audioBlob, 'voice.webm');
            formData.append('sessionId', sessionId); 

            try {
                const response = await fetch(WEBHOOK_URL, {
                    method: 'POST',
                    body: formData
                });

                if (!response.ok) throw new Error("Server Error");

                const json = await response.json();
                handleResponse(json);

            } catch (err) {
                console.error(err);
                document.body.classList.remove('is-processing');
                statusEl.innerText = "Connection Error";
                statusEl.style.color = "var(--error)";
            }
        }

        function handleResponse(data) {
            // Debugging: Print the exact data from n8n to the browser console
            console.log("Data received from n8n:", data); 
        
            // Remove processing state
            document.body.classList.remove('is-processing');
            
            // Check if voice_response exists directly, or if it's nested in .output
            const message = data.voice_response || (data.output && data.output.voice_response) || "Sorry, I didn't catch that.";
        
            statusEl.innerText = "Assistant says:";
            statusEl.style.color = "var(--primary)";
        
            // Show Chat Bubble
            responseBox.innerText = message;
            responseBox.classList.add('visible');
        
            // Speak Audio
            speak(message);
        }

        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const britishVoice = voices.find(v => v.lang.includes('GB') || v.name.includes('UK'));
            
            if (britishVoice) utterance.voice = britishVoice;
            utterance.rate = 1.0;
            
            window.speechSynthesis.speak(utterance);
        }
    </script>
</body>

</html>
